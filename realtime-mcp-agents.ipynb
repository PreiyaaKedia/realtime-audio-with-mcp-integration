{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf236e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ \u001b[1;32mNotebook initialized\u001b[0m ‚åö 14:46:52.995972 \n"
     ]
    }
   ],
   "source": [
    "import os, sys, json\n",
    "sys.path.insert(1, './shared')  # add the shared directory to the Python path\n",
    "import utils\n",
    "\n",
    "deployment_name = os.path.basename(os.path.dirname(globals()['__vsc_ipynb_file__']))\n",
    "resource_group_name = \"rg-realtime-mcp-demo-v5\"\n",
    "resource_group_location = \"eastus2\"\n",
    "\n",
    "apim_sku = 'Basicv2'\n",
    "\n",
    "# gpt-4o-realtime and gpt-4o-mini-realtime are only available for eastuse2 or swedencentral\n",
    "openai_resources = [ {\"name\": \"azure-openai-sc-priya\", \"location\": \"eastus2\"}]\n",
    "openai_deployment_name = \"gpt-4o-realtime-preview\"\n",
    "openai_model_name = \"gpt-4o-realtime-preview\"\n",
    "openai_model_version = \"2024-12-17\"\n",
    "openai_model_sku = \"GlobalStandard\"\n",
    "openai_model_capacity = 5\n",
    "openai_api_version = \"2024-10-01-preview\"\n",
    "\n",
    "build = 0\n",
    "weather_mcp_server_image = \"weather-mcp-server\"\n",
    "weather_mcp_server_src = \"src/weather/mcp-server\"\n",
    "\n",
    "servicenow_mcp_server_image = \"servicenow-mcp-server\"\n",
    "servicenow_mcp_server_src = \"src/servicenow/mcp-server\"\n",
    "servicenow_instance_name = \"\" # Add here the name of your ServiceNow instance, e.g. \"businessname-dev\". Leave empty if you don't want to use ServiceNow.\n",
    "\n",
    "spotify_mcp_server_image = \"spotify-mcp-server\"\n",
    "spotify_mcp_server_src = \"src/spotify/mcp-server\"\n",
    "\n",
    "utils.print_ok('Notebook initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f5dc87",
   "metadata": {},
   "source": [
    "## Verify the Azure CLI and connected Azure subscription\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df14af27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è \u001b[1;34mRunning: az account show \u001b[0m\n",
      "‚úÖ \u001b[1;32mRetrieved az account\u001b[0m ‚åö 14:46:57.265912 [0m:2s]\n",
      "üëâüèΩ \u001b[1;34mCurrent user: priyakedia@microsoft.com\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mTenant ID: 16b3c013-d300-468d-ac64-7eda0820b6d3\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mSubscription ID: 8cebb108-a4d5-402b-a0c4-f7556126277f\u001b[0m\n",
      "‚úÖ \u001b[1;32mRetrieved az account\u001b[0m ‚åö 14:46:57.265912 [0m:2s]\n",
      "üëâüèΩ \u001b[1;34mCurrent user: priyakedia@microsoft.com\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mTenant ID: 16b3c013-d300-468d-ac64-7eda0820b6d3\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mSubscription ID: 8cebb108-a4d5-402b-a0c4-f7556126277f\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "output = utils.run(\"az account show\", \"Retrieved az account\", \"Failed to get the current az account\")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    current_user = output.json_data['user']['name']\n",
    "    tenant_id = output.json_data['tenantId']\n",
    "    subscription_id = output.json_data['id']\n",
    "\n",
    "    utils.print_info(f\"Current user: {current_user}\")\n",
    "    utils.print_info(f\"Tenant ID: {tenant_id}\")\n",
    "    utils.print_info(f\"Subscription ID: {subscription_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd413e9",
   "metadata": {},
   "source": [
    "## 2. Create Deployment using Bicep\n",
    "\n",
    "This lab uses Bicep to declarative define all the resources that will be deployed in the specified resource group. Change the parameters or the main.bicep directly to try different configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d006f616",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install azure-mgmt-apimanagement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce602d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "from azure.mgmt.apimanagement import ApiManagementClient\n",
    "\n",
    "\"\"\"\n",
    "# PREREQUISITES\n",
    "    pip install azure-identity\n",
    "    pip install azure-mgmt-apimanagement\n",
    "# USAGE\n",
    "    python api_management_deleted_services_purge.py\n",
    "\n",
    "    Before run the sample, please set the values of the client ID, tenant ID and client secret\n",
    "    of the AAD application as environment variables: AZURE_CLIENT_ID, AZURE_TENANT_ID,\n",
    "    AZURE_CLIENT_SECRET. For more info about how to get the value, please see:\n",
    "    https://docs.microsoft.com/azure/active-directory/develop/howto-create-service-principal-portal\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def main():\n",
    "    client = ApiManagementClient(\n",
    "        credential=DefaultAzureCredential(),\n",
    "        subscription_id=\"8cebb108-a4d5-402b-a0c4-f7556126277f\",\n",
    "    )\n",
    "\n",
    "    response = client.deleted_services.begin_purge(\n",
    "        service_name=\"apim-dy7dbipcowwgk\",\n",
    "        location=\"eastus2\",\n",
    "    ).result()\n",
    "    print(response)\n",
    "\n",
    "\n",
    "# x-ms-original-file: specification/apimanagement/resource-manager/Microsoft.ApiManagement/stable/2024-05-01/examples/ApiManagementDeletedServicesPurge.json\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0119054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the resource group if doesn't exist\n",
    "utils.create_resource_group(resource_group_name, resource_group_location)\n",
    "\n",
    "# Define the Bicep parameters\n",
    "bicep_parameters = {\n",
    "    \"$schema\": \"https://schema.management.azure.com/schemas/2019-04-01/deploymentParameters.json#\",\n",
    "    \"contentVersion\": \"1.0.0.0\",\n",
    "    \"parameters\": {\n",
    "        \"apimSku\": { \"value\": apim_sku },\n",
    "        \"openAIConfig\": { \"value\": openai_resources },\n",
    "        \"openAIDeploymentName\": { \"value\": openai_deployment_name},\n",
    "        \"openAIModelName\": { \"value\": openai_model_name },\n",
    "        \"openAIModelVersion\": { \"value\": openai_model_version },\n",
    "        \"openAIModelSKU\": { \"value\": openai_model_sku },\n",
    "        \"openAIModelCapacity\": { \"value\": openai_model_capacity },\n",
    "        \"openAIAPIVersion\": { \"value\": openai_api_version },\n",
    "        \"serviceNowInstanceName\": { \"value\": servicenow_instance_name }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Write the parameters to the params.json file\n",
    "with open('params.json', 'w') as bicep_parameters_file:\n",
    "    bicep_parameters_file.write(json.dumps(bicep_parameters))\n",
    "\n",
    "# Run the deployment\n",
    "output = utils.run(f\"az deployment group create --name {deployment_name} --resource-group {resource_group_name} --template-file main.bicep --parameters params.json\",\n",
    "    f\"Deployment '{deployment_name}' succeeded\", f\"Deployment '{deployment_name}' failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128e555e",
   "metadata": {},
   "source": [
    "## Get the deployment Outputs\n",
    "\n",
    "Retrieve the required outputs from previous bicep deployment step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ce2441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain all of the outputs from the deployment\n",
    "output = utils.run(f\"az deployment group show --name {deployment_name} -g {resource_group_name}\", f\"Retrieved deployment: {deployment_name}\", f\"Failed to retrieve deployment: {deployment_name}\")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    apim_service_id = utils.get_deployment_output(output, 'apimServiceId', 'APIM Service Id')\n",
    "    apim_resource_gateway_url = utils.get_deployment_output(output, 'apimResourceGatewayURL', 'APIM Gateway URL')\n",
    "    apim_resource_name = utils.get_deployment_output(output, 'apimResourceName', 'APIM Resource Name')\n",
    "    apim_subscription_key = utils.get_deployment_output(output, 'apimSubscriptionKey', 'APIM Subscription Key (masked)', True)\n",
    "    app_insights_name = utils.get_deployment_output(output, 'applicationInsightsName', 'Application Insights Name')\n",
    "    container_registry_name = utils.get_deployment_output(output, 'containerRegistryName', 'Container Registry Name')\n",
    "    weather_containerapp_resource_name = utils.get_deployment_output(output, 'weatherMCPServerContainerAppResourceName', 'Weather Container App Resource Name')\n",
    "    if servicenow_instance_name:\n",
    "        servicenow_containerapp_resource_name = utils.get_deployment_output(output, 'servicenowMCPServerContainerAppResourceName', 'servicenow Container App Resource Name')\n",
    "    spotify_containerapp_resource_name = utils.get_deployment_output(output, 'spotifyMCPServerContainerAppResourceName', 'Spotify Container App Resource Name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726f2d40",
   "metadata": {},
   "source": [
    "## Build and Deploy MCP Servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bde6d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "build = build + 1 # increment the build number\n",
    "\n",
    "utils.run(f\"az acr build --image {weather_mcp_server_image}:v0.{build} --resource-group {resource_group_name} --registry {container_registry_name} --file {weather_mcp_server_src}/Dockerfile {weather_mcp_server_src}/. --no-logs\", \n",
    "         \"Weather MCP Server image was successfully built\", \"Failed to build the Weather MCP Server image\")\n",
    "utils.run(f'az containerapp update -n {weather_containerapp_resource_name} -g {resource_group_name} --image \"{container_registry_name}.azurecr.io/{weather_mcp_server_image}:v0.{build}\"', \n",
    "         \"Weather MCP Server deployment succeeded\", \"Weather MCP Server deployment failed\")\n",
    "\n",
    "if servicenow_instance_name:\n",
    "    utils.run(f\"az acr build --image {servicenow_mcp_server_image}:v0.{build} --resource-group {resource_group_name} --registry {container_registry_name} --file {servicenow_mcp_server_src}/Dockerfile {servicenow_mcp_server_src}/. --no-logs\", \n",
    "            \"ServiceNow MCP Server image was successfully built\", \"Failed to build the ServiceNow MCP Server image\")\n",
    "    utils.run(f'az containerapp update -n {servicenow_containerapp_resource_name} -g {resource_group_name} --image \"{container_registry_name}.azurecr.io/{servicenow_mcp_server_image}:v0.{build}\"', \n",
    "            \"ServiceNow MCP Server deployment succeeded\", \"ServiceNow MCP Server deployment failed\")\n",
    "\n",
    "utils.run(f\"az acr build --image {spotify_mcp_server_image}:v0.{build} --resource-group {resource_group_name} --registry {container_registry_name} --file {spotify_mcp_server_src}/Dockerfile {spotify_mcp_server_src}/. --no-logs\", \n",
    "          \"Spotify MCP Server image was successfully built\", \"Failed to build the Spotify MCP Server image\")\n",
    "utils.run(f'az containerapp update -n {spotify_containerapp_resource_name} -g {resource_group_name} --image \"{container_registry_name}.azurecr.io/{spotify_mcp_server_image}:v0.{build}\"', \n",
    "          \"Spotify MCP Server deployment succeeded\", \"Spotify MCP Server deployment failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76bb1247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Connected to server https://apim-rydm3isbc5cmc.azure-api.net/spotify/mcp/sse\n",
      "‚öôÔ∏è Tools:\n",
      "  - authorize_spotify\n",
      "     Input Schema: {'properties': {}, 'title': 'authorize_spotifyArguments', 'type': 'object'}\n",
      "  - get_user_playlists\n",
      "     Input Schema: {'properties': {}, 'title': 'get_user_playlistsArguments', 'type': 'object'}\n",
      "  - get_player_queue\n",
      "     Input Schema: {'properties': {}, 'title': 'get_player_queueArguments', 'type': 'object'}\n",
      "  - get_playback_status\n",
      "     Input Schema: {'properties': {}, 'title': 'get_playback_statusArguments', 'type': 'object'}\n",
      "  - start_playback\n",
      "     Input Schema: {'properties': {}, 'title': 'start_playbackArguments', 'type': 'object'}\n",
      "  - pause_playback\n",
      "     Input Schema: {'properties': {}, 'title': 'pause_playbackArguments', 'type': 'object'}\n",
      "  - get_my_queue\n",
      "     Input Schema: {'properties': {}, 'title': 'get_my_queueArguments', 'type': 'object'}\n",
      "  - browse_new_releases\n",
      "     Input Schema: {'properties': {}, 'title': 'browse_new_releasesArguments', 'type': 'object'}\n",
      "  - search\n",
      "     Input Schema: {'properties': {'query': {'title': 'Query', 'type': 'string'}}, 'required': ['query'], 'title': 'searchArguments', 'type': 'object'}\n",
      "  - check_authorization_status\n",
      "     Input Schema: {'properties': {}, 'title': 'check_authorization_statusArguments', 'type': 'object'}\n",
      "  - check_and_repair_authorization\n",
      "     Input Schema: {'properties': {}, 'title': 'check_and_repair_authorizationArguments', 'type': 'object'}\n",
      "  - verify_authorization_with_test_call\n",
      "     Input Schema: {'properties': {}, 'title': 'verify_authorization_with_test_callArguments', 'type': 'object'}\n",
      "  - test_connection\n",
      "     Input Schema: {'properties': {}, 'title': 'test_connectionArguments', 'type': 'object'}\n",
      "  - check_environment_variables\n",
      "     Input Schema: {'properties': {}, 'title': 'check_environment_variablesArguments', 'type': 'object'}\n",
      "‚úÖ Connected to server https://apim-rydm3isbc5cmc.azure-api.net/weather/sse\n",
      "‚öôÔ∏è Tools:\n",
      "  - get_cities\n",
      "     Input Schema: {'properties': {'country': {'title': 'Country', 'type': 'string'}}, 'required': ['country'], 'title': 'get_citiesArguments', 'type': 'object'}\n",
      "  - get_weather\n",
      "     Input Schema: {'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'get_weatherArguments', 'type': 'object'}\n",
      "‚úÖ Connected to server https://apim-rydm3isbc5cmc.azure-api.net/weather/sse\n",
      "‚öôÔ∏è Tools:\n",
      "  - get_cities\n",
      "     Input Schema: {'properties': {'country': {'title': 'Country', 'type': 'string'}}, 'required': ['country'], 'title': 'get_citiesArguments', 'type': 'object'}\n",
      "  - get_weather\n",
      "     Input Schema: {'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'get_weatherArguments', 'type': 'object'}\n"
     ]
    }
   ],
   "source": [
    "import os, json, asyncio, time, requests\n",
    "from mcp import ClientSession\n",
    "from mcp.client.sse import sse_client\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def list_tools(server_url, authorization_header = None):\n",
    "    headers = {\"Authorization\": authorization_header} if authorization_header else None\n",
    "    async with sse_client(server_url, headers) as streams:\n",
    "        async with ClientSession(streams[0], streams[1]) as session:\n",
    "            await session.initialize()\n",
    "\n",
    "            response = await session.list_tools()\n",
    "            tools = response.tools\n",
    "    print(f\"‚úÖ Connected to server {server_url}\")\n",
    "    print(\"‚öôÔ∏è Tools:\")\n",
    "    for tool in tools:\n",
    "        print(f\"  - {tool.name}\")\n",
    "        print(f\"     Input Schema: {tool.inputSchema}\")\n",
    "\n",
    "apim_resource_gateway_url = \"https://apim-rydm3isbc5cmc.azure-api.net\"   \n",
    "\n",
    "asyncio.run(list_tools(f\"{apim_resource_gateway_url}/spotify/mcp/sse\"))\n",
    "asyncio.run(list_tools(f\"{apim_resource_gateway_url}/weather/sse\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d267e03",
   "metadata": {},
   "source": [
    "## Execute a Realtime Semantic Kernel Agent using MCP Tools via Azure API Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b33538a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service_event=ResponseTextDoneEvent(content_index=0, event_id='event_BZwN3tWdKN2Ixrf9N29iX', item_id='item_BZwN3cxsuHsx4DEbDzr3Q', output_index=0, response_id='resp_BZwN3yfIVgimLyRMaElwL', text='Hello! How can I assist you today?', type='response.text.done') service_type='response.text.done'"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.connectors.ai.open_ai import (\n",
    "    AzureRealtimeWebsocket,\n",
    "    AzureRealtimeExecutionSettings,\n",
    "    ListenEvents,\n",
    "    TurnDetection\n",
    ")\n",
    "from semantic_kernel.contents import RealtimeTextEvent\n",
    "from semantic_kernel.contents.text_content import TextContent\n",
    "from semantic_kernel.connectors.mcp import MCPSsePlugin\n",
    "\n",
    "realtime_agent = AzureRealtimeWebsocket(\n",
    "            endpoint=f\"{apim_resource_gateway_url}/rt-audio\",\n",
    "            deployment_name=openai_deployment_name,\n",
    "            azure_openai_realtime_deployment_name=openai_deployment_name,\n",
    "            api_key=apim_subscription_key,\n",
    "            api_version=openai_api_version)\n",
    "\n",
    "weather_plugin = MCPSsePlugin(\n",
    "    name=\"Weather\",\n",
    "    url=f\"{apim_resource_gateway_url}/weather/sse\",\n",
    "    description=\"Weather Plugin\",\n",
    ")\n",
    "    \n",
    "settings = AzureRealtimeExecutionSettings(modalities=[\"text\"], turn_detection=TurnDetection(type=\"server_vad\", create_response=True, silence_duration_ms=800, threshold=0.8),\n",
    "\n",
    "                                          instructions=\"You are a helpful assistant that provides information about the weather, using just the text modality\",)\n",
    "async with realtime_agent(settings=settings, create_response=True, plugins=[weather_plugin]) as connection:\n",
    "    await connection.send(RealtimeTextEvent(text=TextContent(text=\"What's the weather like in Bangalore?\")))\n",
    "\n",
    "    async for event in connection.receive():\n",
    "        if event.service_type == \"response.text.done\":\n",
    "            print(event, flush=True, end=\"\")\n",
    "        elif event.service_type == \"response.done\":\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e2be60",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Create a Spotify OAuth app and configure the credential provider\n",
    "Step 1 - Create an account on Spotify Developer portal\n",
    "\n",
    "Step 2 - Create an app with redirect URI from the next step\n",
    "üëâ Use the Authorization callback URL that is provided below\n",
    "üëâ Copy the Client ID and Client secret\n",
    "\n",
    "Step 3 - Configure the credential provider in API Management\n",
    "üëâ You just need to update the Client ID and Client secret on the existing spotify credential manager provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97081466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authorization callback URL: https://authorization-manager.consent.azure-apim.net/redirect/apim/apim-rydm3isbc5cmc\n"
     ]
    }
   ],
   "source": [
    "print(f\"Authorization callback URL: https://authorization-manager.consent.azure-apim.net/redirect/apim/{apim_resource_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217c4403",
   "metadata": {},
   "source": [
    "Test the Realtime API using FastRTC + Gradio\n",
    "\n",
    "FastRTC is an elegant realtime library communication library to enable you to easily and quickly build RTC application both using websockets and WebRTC.\n",
    "\n",
    "Please ensure you have run the pip command succefully to install all required packages\n",
    "\n",
    "üëâ Tip: Restart the Python Kernel to stop the FastRTC server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5ccc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Initializing all MCPs\n",
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Initializing all MCPs\n",
      "{'authorize_spotify': 'spotify', 'get_user_playlists': 'spotify', 'get_player_queue': 'spotify', 'get_playback_status': 'spotify', 'start_playback': 'spotify', 'pause_playback': 'spotify', 'get_my_queue': 'spotify', 'browse_new_releases': 'spotify', 'search': 'spotify', 'check_authorization_status': 'spotify', 'check_and_repair_authorization': 'spotify', 'verify_authorization_with_test_call': 'spotify', 'test_connection': 'spotify', 'check_environment_variables': 'spotify', 'get_cities': 'weather', 'get_weather': 'weather'}\n",
      "echo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\fastrtc\\utils.py\", line 474, in async_wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\priyakedia\\AppData\\Local\\Temp\\ipykernel_32196\\1921268966.py\", line 72, in start_up\n",
      "    async for event in self.connection:\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\openai\\resources\\beta\\realtime\\realtime.py\", line 258, in __aiter__\n",
      "    yield await self.recv()\n",
      "          ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\openai\\resources\\beta\\realtime\\realtime.py\", line 268, in recv\n",
      "    return self.parse_event(await self.recv_bytes())\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\openai\\resources\\beta\\realtime\\realtime.py\", line 278, in recv_bytes\n",
      "    message = await self._connection.recv(decode=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\websockets\\asyncio\\connection.py\", line 322, in recv\n",
      "    raise self.protocol.close_exc from self.recv_exc\n",
      "websockets.exceptions.ConnectionClosedError: sent 1011 (internal error) keepalive ping timeout; no close frame received\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\fastrtc\\utils.py\", line 474, in async_wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\priyakedia\\AppData\\Local\\Temp\\ipykernel_32196\\1921268966.py\", line 119, in receive\n",
      "    await self.connection.input_audio_buffer.append(audio=audio_message)  # type: ignore\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\openai\\resources\\beta\\realtime\\realtime.py\", line 941, in append\n",
      "    await self._connection.send(\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\openai\\resources\\beta\\realtime\\realtime.py\", line 288, in send\n",
      "    await self._connection.send(data)\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\websockets\\asyncio\\connection.py\", line 476, in send\n",
      "    async with self.send_context():\n",
      "  File \"C:\\Python312\\Lib\\contextlib.py\", line 210, in __aenter__\n",
      "    return await anext(self.gen)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\websockets\\asyncio\\connection.py\", line 957, in send_context\n",
      "    raise self.protocol.close_exc from original_exc\n",
      "websockets.exceptions.ConnectionClosedError: sent 1011 (internal error) keepalive ping timeout; no close frame received\n",
      "Exception ignored in: <async_generator object sse_client at 0x000001FCA9136CD0>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\priyakedia\\AppData\\Local\\Temp\\ipykernel_32196\\1921268966.py\", line 42, in __init__\n",
      "RuntimeError: async generator ignored GeneratorExit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Initializing all MCPs\n",
      "{'authorize_spotify': 'spotify', 'get_user_playlists': 'spotify', 'get_player_queue': 'spotify', 'get_playback_status': 'spotify', 'start_playback': 'spotify', 'pause_playback': 'spotify', 'get_my_queue': 'spotify', 'browse_new_releases': 'spotify', 'search': 'spotify', 'check_authorization_status': 'spotify', 'check_and_repair_authorization': 'spotify', 'verify_authorization_with_test_call': 'spotify', 'test_connection': 'spotify', 'check_environment_variables': 'spotify', 'get_cities': 'weather', 'get_weather': 'weather'}\n",
      "verse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <async_generator object AsyncClient.stream at 0x000001FCA9154CC0>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1592, in stream\n",
      "    await response.aclose()\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\httpx\\_models.py\", line 1076, in aclose\n",
      "    await self.stream.aclose()\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 182, in aclose\n",
      "    await self._stream.aclose()\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 276, in aclose\n",
      "    await self._httpcore_stream.aclose()\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 412, in aclose\n",
      "    with AsyncShieldCancellation():\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\httpcore\\_synchronization.py\", line 226, in __exit__\n",
      "    self._anyio_shield.__exit__(exc_type, exc_value, traceback)\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 456, in __exit__\n",
      "    if current_task() is not self._host_task:\n",
      "       ^^^^^^^^^^^^^^\n",
      "RuntimeError: no running event loop\n",
      "Exception ignored in: <async_generator object sse_client at 0x000001FCA9137CA0>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\priyakedia\\AppData\\Local\\Temp\\ipykernel_32196\\1921268966.py\", line 42, in __init__\n",
      "RuntimeError: async generator ignored GeneratorExit\n",
      "Exception ignored in: <async_generator object sse_client at 0x000001FCA9134D30>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\priyakedia\\AppData\\Local\\Temp\\ipykernel_32196\\1921268966.py\", line 42, in __init__\n",
      "RuntimeError: async generator ignored GeneratorExit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Initializing all MCPs\n",
      "{'authorize_spotify': 'spotify', 'get_user_playlists': 'spotify', 'get_player_queue': 'spotify', 'get_playback_status': 'spotify', 'start_playback': 'spotify', 'pause_playback': 'spotify', 'get_my_queue': 'spotify', 'browse_new_releases': 'spotify', 'search': 'spotify', 'check_authorization_status': 'spotify', 'check_and_repair_authorization': 'spotify', 'verify_authorization_with_test_call': 'spotify', 'test_connection': 'spotify', 'check_environment_variables': 'spotify', 'get_cities': 'weather', 'get_weather': 'weather'}\n",
      "echo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <async_generator object sse_client at 0x000001FCA9136880>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\priyakedia\\AppData\\Local\\Temp\\ipykernel_32196\\1921268966.py\", line 42, in __init__\n",
      "RuntimeError: async generator ignored GeneratorExit\n",
      "Exception ignored in: <async_generator object sse_client at 0x000001FCA9135D00>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\priyakedia\\AppData\\Local\\Temp\\ipykernel_32196\\1921268966.py\", line 42, in __init__\n",
      "RuntimeError: async generator ignored GeneratorExit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Initializing all MCPs\n",
      "{'authorize_spotify': 'spotify', 'get_user_playlists': 'spotify', 'get_player_queue': 'spotify', 'get_playback_status': 'spotify', 'start_playback': 'spotify', 'pause_playback': 'spotify', 'get_my_queue': 'spotify', 'browse_new_releases': 'spotify', 'search': 'spotify', 'check_authorization_status': 'spotify', 'check_and_repair_authorization': 'spotify', 'verify_authorization_with_test_call': 'spotify', 'test_connection': 'spotify', 'check_environment_variables': 'spotify', 'get_cities': 'weather', 'get_weather': 'weather'}\n",
      "coral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\fastrtc\\utils.py\", line 474, in async_wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\priyakedia\\AppData\\Local\\Temp\\ipykernel_32196\\1921268966.py\", line 83, in start_up\n",
      "    await self.get_tool_response(event)\n",
      "  File \"C:\\Users\\priyakedia\\AppData\\Local\\Temp\\ipykernel_32196\\1921268966.py\", line 170, in get_tool_response\n",
      "    server_name = self.tool_server_map[event.name]\n",
      "                  ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "KeyError: 'add_to_playlist'\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\fastrtc\\utils.py\", line 474, in async_wrapper\n",
      "    return await func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\priyakedia\\AppData\\Local\\Temp\\ipykernel_32196\\1921268966.py\", line 119, in receive\n",
      "    await self.connection.input_audio_buffer.append(audio=audio_message)  # type: ignore\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\openai\\resources\\beta\\realtime\\realtime.py\", line 941, in append\n",
      "    await self._connection.send(\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\openai\\resources\\beta\\realtime\\realtime.py\", line 288, in send\n",
      "    await self._connection.send(data)\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\websockets\\asyncio\\connection.py\", line 476, in send\n",
      "    async with self.send_context():\n",
      "  File \"C:\\Python312\\Lib\\contextlib.py\", line 210, in __aenter__\n",
      "    return await anext(self.gen)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\websockets\\asyncio\\connection.py\", line 957, in send_context\n",
      "    raise self.protocol.close_exc from original_exc\n",
      "websockets.exceptions.ConnectionClosedOK: sent 1000 (OK); then received 1000 (OK)\n",
      "Exception ignored in: <async_generator object AsyncClient.stream at 0x000001FCA9154810>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1592, in stream\n",
      "    await response.aclose()\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\httpx\\_models.py\", line 1076, in aclose\n",
      "    await self.stream.aclose()\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 182, in aclose\n",
      "    await self._stream.aclose()\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 276, in aclose\n",
      "    await self._httpcore_stream.aclose()\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 412, in aclose\n",
      "    with AsyncShieldCancellation():\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\httpcore\\_synchronization.py\", line 226, in __exit__\n",
      "    self._anyio_shield.__exit__(exc_type, exc_value, traceback)\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 457, in __exit__\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempted to exit cancel scope in a different task than it was entered in\n",
      "Exception ignored in: <async_generator object AsyncClient.stream at 0x000001FCA9186430>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1592, in stream\n",
      "    await response.aclose()\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\httpx\\_models.py\", line 1076, in aclose\n",
      "    await self.stream.aclose()\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 182, in aclose\n",
      "    await self._stream.aclose()\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 276, in aclose\n",
      "    await self._httpcore_stream.aclose()\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 412, in aclose\n",
      "    with AsyncShieldCancellation():\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\httpcore\\_synchronization.py\", line 226, in __exit__\n",
      "    self._anyio_shield.__exit__(exc_type, exc_value, traceback)\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 457, in __exit__\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempted to exit cancel scope in a different task than it was entered in\n",
      "Exception ignored in: <async_generator object AsyncClient.stream at 0x000001FCA9154CC0>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1592, in stream\n",
      "    await response.aclose()\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\httpx\\_models.py\", line 1076, in aclose\n",
      "    await self.stream.aclose()\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 182, in aclose\n",
      "    await self._stream.aclose()\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 276, in aclose\n",
      "    await self._httpcore_stream.aclose()\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 412, in aclose\n",
      "    with AsyncShieldCancellation():\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\httpcore\\_synchronization.py\", line 226, in __exit__\n",
      "    self._anyio_shield.__exit__(exc_type, exc_value, traceback)\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 457, in __exit__\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempted to exit cancel scope in a different task than it was entered in\n",
      "Exception ignored in: <async_generator object AsyncClient.stream at 0x000001FCA902DF80>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1592, in stream\n",
      "    await response.aclose()\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\httpx\\_models.py\", line 1076, in aclose\n",
      "    await self.stream.aclose()\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 182, in aclose\n",
      "    await self._stream.aclose()\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 276, in aclose\n",
      "    await self._httpcore_stream.aclose()\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 412, in aclose\n",
      "    with AsyncShieldCancellation():\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\httpcore\\_synchronization.py\", line 226, in __exit__\n",
      "    self._anyio_shield.__exit__(exc_type, exc_value, traceback)\n",
      "  File \"c:\\Users\\priyakedia\\projects\\realtime-audio-with-mcp-integration\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 457, in __exit__\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Attempted to exit cancel scope in a different task than it was entered in\n",
      "Error in sse_reader: \n",
      "Error in sse_reader: \n"
     ]
    }
   ],
   "source": [
    "import asyncio, base64, json, random, openai\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "from openai.types.beta.realtime import ResponseAudioTranscriptDoneEvent, ConversationItemCreateEvent\n",
    "from fastrtc import (\n",
    "    AdditionalOutputs,\n",
    "    AsyncStreamHandler,\n",
    "    Stream,\n",
    "    wait_for_item,\n",
    "    UIArgs\n",
    ")\n",
    "from gradio.utils import get_space\n",
    "from mcp_client import OAI_RT_SSEMCPClient\n",
    "\n",
    "# Define the sample rate (Hz)\n",
    "SAMPLE_RATE = 24000\n",
    "\n",
    "AZURE_OPENAI_API_ENDPOINT = apim_resource_gateway_url + \"/rt-audio\"\n",
    "AZURE_OPENAI_API_KEY = apim_subscription_key\n",
    "AZURE_OPENAI_API_VERSION = openai_api_version\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME = openai_deployment_name\n",
    "\n",
    "class OpenAIHandler(AsyncStreamHandler):\n",
    "    mcp_config = {\n",
    "        'spotify': f\"{apim_resource_gateway_url}/spotify/mcp/sse\",\n",
    "        'weather': f\"{apim_resource_gateway_url}/weather/sse\"\n",
    "        }\n",
    "    mcp_servers = {}\n",
    "    tool_server_map = {}\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(\n",
    "            expected_layout=\"mono\",\n",
    "            output_sample_rate=SAMPLE_RATE,\n",
    "            output_frame_size=480,  # In this example we choose 480 samples per frame.\n",
    "            input_sample_rate=SAMPLE_RATE,\n",
    "        )\n",
    "        self.connection = None\n",
    "        if len(self.mcp_config) > 0:\n",
    "            print (\"‚öôÔ∏è Initializing all MCPs\")\n",
    "            for name, url in self.mcp_config.items():\n",
    "                self.mcp_servers[name] = OAI_RT_SSEMCPClient(server_name=name, url=url)\n",
    "        else:\n",
    "            print (\"no MCPs\")\n",
    "        self.output_queue = asyncio.Queue()\n",
    "\n",
    "    async def start_up(self):\n",
    "        \"\"\"\n",
    "        Establish a persistent realtime connection to the Azure OpenAI backend.\n",
    "        The connection is configured for server‚Äêside Voice Activity Detection.\n",
    "        \"\"\"\n",
    "        self.client = openai.AsyncAzureOpenAI(\n",
    "            azure_endpoint=AZURE_OPENAI_API_ENDPOINT,\n",
    "            azure_deployment=AZURE_OPENAI_DEPLOYMENT_NAME,\n",
    "            api_key=AZURE_OPENAI_API_KEY,\n",
    "            api_version=AZURE_OPENAI_API_VERSION,\n",
    "        )\n",
    "        for name, server in self.mcp_servers.items():\n",
    "                await server.start()\n",
    "        # When using Azure OpenAI realtime (beta), set the model/deployment identifier\n",
    "        async with self.client.beta.realtime.connect(\n",
    "            model=AZURE_OPENAI_DEPLOYMENT_NAME  # Replace with your deployed realtime model id on Azure OpenAI.\n",
    "        ) as conn:\n",
    "            # Configure the session to use server-based voice activity detection (VAD)\n",
    "            session_config = await self.session_config()\n",
    "            await conn.session.update(session=session_config) # type: ignore\n",
    "            self.connection = conn\n",
    "\n",
    "            # Uncomment the following line to send a welcome message to the assistant.\n",
    "            # await self.welcome()\n",
    "\n",
    "            async for event in self.connection:\n",
    "                # Handle interruptions\n",
    "                if event.type == \"input_audio_buffer.speech_started\":\n",
    "                    self.clear_queue()\n",
    "                if event.type == \"conversation.item.input_audio_transcription.completed\":\n",
    "                    # This event signals that an input audio transcription is completed.\n",
    "                    await self.output_queue.put(AdditionalOutputs(event))\n",
    "                if event.type == \"response.audio_transcript.done\":\n",
    "                    # This event signals that a response audio transcription is completed.\n",
    "                    await self.output_queue.put(AdditionalOutputs(event))\n",
    "                if event.type == \"response.function_call_arguments.done\":\n",
    "                    await self.get_tool_response(event)\n",
    "                if event.type == \"conversation.item.created\":\n",
    "                    await self.output_queue.put(AdditionalOutputs(event))\n",
    "                if event.type == \"response.audio.delta\":\n",
    "                    # For incremental audio output events, decode the delta.\n",
    "                    await self.output_queue.put(\n",
    "                        (\n",
    "                            self.output_sample_rate,\n",
    "                            np.frombuffer(base64.b64decode(event.delta), dtype=np.int16).reshape(1, -1),\n",
    "                        ),\n",
    "                    )\n",
    "\n",
    "    def copy(self):\n",
    "        return OpenAIHandler()\n",
    "\n",
    "    async def welcome(self):\n",
    "        await self.connection.conversation.item.create( # type: ignore\n",
    "            item={\n",
    "                \"type\": \"message\",\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [{\"type\": \"input_text\", \"text\": \"what's your name?\"}],\n",
    "            }\n",
    "        )\n",
    "        await self.connection.response.create() # type: ignore\n",
    "\n",
    "    async def receive(self, frame: tuple[int, np.ndarray]) -> None:\n",
    "        \"\"\"\n",
    "        Receives an audio frame from the stream and sends it into the realtime API.\n",
    "        The audio data is encoded as Base64 before appending to the connection's input.\n",
    "        \"\"\"\n",
    "        if not self.connection:\n",
    "            return\n",
    "        _, array = frame\n",
    "        array = array.squeeze()\n",
    "        # Encode audio as Base64 string\n",
    "        audio_message = base64.b64encode(array.tobytes()).decode(\"utf-8\")\n",
    "        await self.connection.input_audio_buffer.append(audio=audio_message)  # type: ignore\n",
    "\n",
    "    async def emit(self) -> tuple[int, np.ndarray] | AdditionalOutputs | None:\n",
    "        \"\"\"\n",
    "        Waits for and returns the next output from the output queue.\n",
    "        The output may be an audio chunk or an additional output such as transcription.\n",
    "        \"\"\"\n",
    "        return await wait_for_item(self.output_queue)\n",
    "\n",
    "    async def shutdown(self) -> None: # type: ignore\n",
    "        # await self.weather_mcp.stop()\n",
    "        if self.connection:\n",
    "            await self.connection.close()\n",
    "            self.connection = None\n",
    "\n",
    "    async def session_config(self):\n",
    "        \"\"\"Returns a random value from the predefined list.\"\"\"\n",
    "        values = ['alloy', 'ash', 'ballad', 'coral', 'echo', 'sage', 'shimmer', 'verse']\n",
    "        tools = []\n",
    "        ### Get all tools from all active servers\n",
    "        for name, server in self.mcp_servers.items():\n",
    "                current_server_tools = await server.list_tools()\n",
    "                for tool in current_server_tools:\n",
    "                    self.tool_server_map[tool['name']]= name\n",
    "                tools = tools + current_server_tools\n",
    "        print(self.tool_server_map)\n",
    "        voice = random.choice(values)\n",
    "        print(voice)\n",
    "        ### for details on available param: https://platform.openai.com/docs/api-reference/realtime-sessions/create\n",
    "        SESSION_CONFIG={\n",
    "            \"input_audio_transcription\": {\n",
    "                \"model\": \"whisper-1\",\n",
    "            },\n",
    "            \"turn_detection\": {\n",
    "                \"threshold\": 0.4,\n",
    "                \"silence_duration_ms\": 600,\n",
    "                \"type\": \"server_vad\"\n",
    "            },\n",
    "            \"instructions\": f\"\"\"You are a DJ named {voice}! \n",
    "                                You are a helpful, calm and cheerful agent who responds with a clam accent, but also can speak in any language or accent. \n",
    "                                If you need to call a spotify tool, inform the user that you need first to call the authorization tool.\n",
    "                                After calling the authorization tool, send a text event with the link URL and don't read the link.\n",
    "                                After sending the event with the link, inform the user that he just needs to click on the provide link to get authorized on Spotify.\"\"\",\n",
    "            \"voice\": voice,\n",
    "            \"modalities\": [\"text\", \"audio\"], ## required to solicit the initial welcome message\n",
    "            \"tools\": tools\n",
    "        }\n",
    "        return SESSION_CONFIG\n",
    "\n",
    "    async def get_tool_response(self, event):\n",
    "        ### findout which MCP server to call\n",
    "        server_name = self.tool_server_map[event.name]\n",
    "        ### call the target\n",
    "        response = await self.mcp_servers[server_name].call_tool(tool_call=event.model_dump())\n",
    "        await self.connection.conversation.item.create(item=response) # type: ignore\n",
    "        await self.connection.response.create() # type: ignore\n",
    "\n",
    "def on_open(ws):\n",
    "    print(\"Connected to server.\")\n",
    "\n",
    "def on_message(ws, message):\n",
    "    data = json.loads(message)\n",
    "    print(\"Received event:\", json.dumps(data, indent=2))\n",
    "\n",
    "def update_chatbot(chatbot: list[dict], event):\n",
    "    \"\"\"\n",
    "    Append the completed transcription to the chatbot messages.\n",
    "    \"\"\"\n",
    "    if event.type == \"conversation.item.input_audio_transcription.completed\":\n",
    "        chatbot.append({\"role\": \"user\", \"content\": event.transcript})\n",
    "    elif event.type == \"response.audio_transcript.done\":\n",
    "        chatbot.append({\"role\": \"assistant\", \"content\": event.transcript})\n",
    "    elif event.type == \"conversation.item.created\":\n",
    "        if event.item and event.item.output:\n",
    "            output = str(event.item.output)\n",
    "            expected_output = \"Please authorize by opening this link:\" # this string must match what was coded in the mcp server\n",
    "            if expected_output in output:\n",
    "                link = f'<a href=\"{output.replace(expected_output, \"\").strip()}\">üëâ Click here to authorize</a>'\n",
    "                chatbot.append({\"role\": \"assistant\", \"content\": link})\n",
    "    return chatbot\n",
    "\n",
    "ui_args: UIArgs = UIArgs(\n",
    "    title=\"APIM ‚ù§Ô∏è MCP - DJ Contoso Assistant üéß\",\n",
    ")\n",
    "chatbot = gr.Chatbot(type=\"messages\")\n",
    "latest_message = gr.Textbox(type=\"text\", visible=True)\n",
    "\n",
    "# Instantiate the Stream object that uses the OpenAIHandler.\n",
    "stream = Stream(\n",
    "    OpenAIHandler(),\n",
    "    mode=\"send-receive\",\n",
    "    modality=\"audio\",\n",
    "    additional_inputs=[chatbot],\n",
    "    additional_outputs=[chatbot],\n",
    "    additional_outputs_handler=update_chatbot,\n",
    "    ui_args=ui_args,\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    stream.ui.launch(server_port=7860)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
